digraph deps {
  rankdir=LR;
  node [shape=box, fontsize=10];
  edge [arrowsize=0.7];
  "lambda._utc_now_iso" [shape=box, tooltip="_utc_now_iso()\nlambda.py:42\n\ndef _utc_now_iso() -&gt; str:\n    return datetime.now(timezone.utc).isoformat()", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:42", target="_top"];
  "lambda.apply_spec_transforms" [shape=box, tooltip="apply_spec_transforms(rec, spec)\nlambda.py:145\n\ndef apply_spec_transforms(rec: Dict[str, Any], spec: Dict[str, Any]) -&gt; Optional[Dict[str, Any]]:\n    if not spec:\n        return rec\n    # rename\n    for src, dst in spec.get(&quot;rename&quot;, {}).items():\n        if src in rec:\n            rec[dst] = rec.pop(src)\n    # drop\n    for f in spec.get(&quot;drop&quot;, []):\n        rec.pop(f, None)\n    # coerce\n    for f, t in spec.get(&quot;coerce&quot;, {}).items():\n        if f in rec:\n            rec[f] = coerce_type(rec[f], t)\n    # derive (safe eval with limited globals)\n    for f, expr in spec.get(&quot;derive&quot;, {}).items():\n        try:\n            rec[f] = eval(expr, {&quot;__builtins__&quot;: {}}, {&quot;record&quot;: rec})\n        except Exception:\n            rec[f] = None\n... (5 more lines)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:145", target="_top"];
  "lambda.coerce_type" [shape=box, tooltip="coerce_type(value, target)\nlambda.py:60\n\ndef coerce_type(value: Any, target: str) -&gt; Any:\n    if value is None or value == &quot;&quot;:\n        return None\n    try:\n        if target == &quot;int&quot;: return int(value)\n        if target == &quot;float&quot;: return float(value)\n        if target == &quot;bool&quot;:\n            if isinstance(value, bool): return value\n            return str(value).strip().lower() in {&quot;1&quot;,&quot;true&quot;,&quot;t&quot;,&quot;yes&quot;,&quot;y&quot;}\n        if target == &quot;str&quot;: return str(value)\n        if target == &quot;iso8601&quot;:\n            # allow unix seconds too\n            if isinstance(value, (int, float)): \n                return datetime.fromtimestamp(float(value), tz=timezone.utc).isoformat()\n            return datetime.fromisoformat(str(value)).astimezone(timezone.utc).isoformat()\n    except Exception:\n        return None\n    return value", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:60", target="_top"];
  "lambda.detect_format" [shape=box, tooltip="detect_format(key, first_line)\nlambda.py:117\n\ndef detect_format(key: str, first_line: Optional[str]) -&gt; str:\n    if key.lower().endswith(&quot;.csv&quot;): return &quot;csv&quot;\n    if key.lower().endswith(&quot;.json&quot;) or key.lower().endswith(&quot;.ndjson&quot;): return &quot;jsonl&quot;\n    # fallback by sniffing\n    if first_line and first_line.strip().startswith(&quot;{&quot;):\n        return &quot;jsonl&quot;\n    return &quot;csv&quot;", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:117", target="_top"];
  "lambda.enrich_record" [shape=box, tooltip="enrich_record(rec, spec)\nlambda.py:179\n\ndef enrich_record(rec: Dict[str, Any], spec: Dict[str, Any]) -&gt; Dict[str, Any]:\n    if not ddb:\n        return rec\n    key_field = spec.get(&quot;enrich_key&quot;) if spec else None\n    key_field = key_field or next(iter(rec.keys()), None)\n    if not key_field or rec.get(key_field) in (None, &quot;&quot;):\n        return rec\n    try:\n        resp = ddb.get_item(Key={key_field: rec[key_field]})\n        if &quot;Item&quot; in resp:\n            # merge with prefix &quot;enrich_&quot; to avoid collisions\n            for k, v in resp[&quot;Item&quot;].items():\n                rec[f&quot;enrich_{k}&quot;] = v\n    except Exception as e:\n        log.debug(&quot;DDB enrich failed: %s&quot;, e)\n    return rec", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:179", target="_top"];
  "lambda.flush" [shape=box, tooltip="flush()\nlambda.py:229\n\n    def flush():\n        nonlocal shard_idx, buf, byte_count\n        if not buf:\n            return None\n        shard_key = f&quot;{base_prefix}/part-{shard_idx:05d}.ndjson.gz&quot;\n        put_s3_gzip_lines(OUTPUT_BUCKET, shard_key, buf)\n        log.info(&quot;Wrote %s records to s3://%s/%s (%d shards)&quot;, len(buf), OUTPUT_BUCKET, shard_key, shard_idx + 1)\n        shard_idx += 1\n        buf = []\n        byte_count = 0", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:229", target="_top"];
  "lambda.get_writer" [shape=box, tooltip="get_writer(pval)\nlambda.py:316\n\n    def get_writer(pval: str):\n        if pval not in writers:\n            # final prefix: .../pkey=val/ingest_date=YYYY-MM-DD\n            ingest = event_time[:10]\n            safe_val = str(pval).replace(&quot;/&quot;, &quot;_&quot;) if pval else &quot;unknown&quot;\n            final_prefix = f&quot;{base_out}/{PARTITION_BY}={safe_val}/ingest_date={ingest}&quot;\n            writers[pval] = shard_writer(final_prefix, event_time)\n        return writers[pval]", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:316", target="_top"];
  "lambda.handler" [shape=box, style=filled, fillcolor=lightblue, tooltip="handler(event, context)\nlambda.py:256\n\ndef handler(event, context):\n    &quot;&quot;&quot;\n    S3 ObjectCreated event → transform → S3 (gzip ndjson)\n    &quot;&quot;&quot;\n    t0 = time.time()\n    # Extract S3 info (supports single-record events)\n    try:\n        rec = event[&quot;Records&quot;][0]\n        s3e = rec[&quot;s3&quot;]\n        bucket = s3e[&quot;bucket&quot;][&quot;name&quot;]\n        key = s3e[&quot;object&quot;][&quot;key&quot;]\n        event_time = rec.get(&quot;eventTime&quot;) or _utc_now_iso()\n    except Exception:\n        # Also allow manual invocation with {&quot;bucket&quot;: &quot;...&quot;, &quot;key&quot;: &quot;...&quot;}\n        bucket = event.get(&quot;bucket&quot;)\n        key = event.get(&quot;key&quot;)\n        event_time = _utc_now_iso()\n    if not bucket or not key:\n        raise ValueError(&quot;Missing S3 bucket/key in event&quot;)\n\n... (112 more lines)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:256", target="_top"];
  "lambda.iter_s3_object_lines" [shape=box, tooltip="iter_s3_object_lines(bucket, key)\nlambda.py:110\n\ndef iter_s3_object_lines(bucket: str, key: str) -&gt; Iterable[str]:\n    obj = s3.get_object(Bucket=bucket, Key=key)\n    body = obj[&quot;Body&quot;]\n    for chunk in body.iter_lines():\n        if chunk:\n            yield chunk.decode(&quot;utf-8&quot;, errors=&quot;replace&quot;)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:110", target="_top"];
  "lambda.load_transform_spec" [shape=box, tooltip="load_transform_spec()\nlambda.py:79\n\ndef load_transform_spec() -&gt; Dict[str, Any]:\n    &quot;&quot;&quot;\n    Optional transform spec from SSM Parameter Store (SecureString or String).\n    Expected structure (example):\n    {\n      &quot;rename&quot;: {&quot;UserID&quot;:&quot;user_id&quot;,&quot;Full Name&quot;:&quot;full_name&quot;},\n      &quot;coerce&quot;: {&quot;user_id&quot;:&quot;int&quot;,&quot;price&quot;:&quot;float&quot;,&quot;created_at&quot;:&quot;iso8601&quot;},\n      &quot;drop&quot;: [&quot;debug&quot;,&quot;unused_field&quot;],\n      &quot;derive&quot;: {\n        &quot;full_name_upper&quot;: &quot;record.get(&#x27;full_name&#x27;,&#x27;&#x27;).upper()&quot;,\n        &quot;order_total&quot;: &quot;(record.get(&#x27;price&#x27;) or 0) * (record.get(&#x27;qty&#x27;) or 1)&quot;\n      },\n      &quot;required&quot;: [&quot;user_id&quot;,&quot;email&quot;],\n      &quot;enrich_key&quot;: &quot;user_id&quot;  # used if ENRICH_DDB_TABLE is set\n    }\n    &quot;&quot;&quot;\n    if not TRANSFORM_SPEC_SSM_PARAM:\n        return {}\n    try:\n        resp = ssm.get_parameter(Name=TRANSFORM_SPEC_SSM_PARAM, WithDecryption=True)\n... (5 more lines)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:79", target="_top"];
  "lambda.mask_fields" [shape=box, tooltip="mask_fields(rec)\nlambda.py:171\n\ndef mask_fields(rec: Dict[str, Any]) -&gt; Dict[str, Any]:\n    if not MASK_FIELDS:\n        return rec\n    for f in MASK_FIELDS:\n        if f in rec and rec[f] is not None:\n            rec[f] = mask_value(rec[f])\n    return rec", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:171", target="_top"];
  "lambda.mask_value" [shape=box, tooltip="mask_value(v)\nlambda.py:55\n\ndef mask_value(v: Any) -&gt; str:\n    &quot;&quot;&quot;Hash-based masking (stable but non-reversible)&quot;&quot;&quot;\n    raw = json.dumps(v, sort_keys=True, ensure_ascii=False).encode(&quot;utf-8&quot;)\n    return hashlib.sha256(raw).hexdigest()", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:55", target="_top"];
  "lambda.normalize_keys" [shape=box, tooltip="normalize_keys(rec)\nlambda.py:142\n\ndef normalize_keys(rec: Dict[str, Any]) -&gt; Dict[str, Any]:\n    return {snake_case(k): v for k, v in rec.items()}", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:142", target="_top"];
  "lambda.object_exists" [shape=box, tooltip="object_exists(bucket, key)\nlambda.py:204\n\ndef object_exists(bucket: str, key: str) -&gt; bool:\n    try:\n        s3.head_object(Bucket=bucket, Key=key)\n        return True\n    except ClientError as e:\n        if e.response[&quot;Error&quot;][&quot;Code&quot;] in (&quot;404&quot;, &quot;NotFound&quot;):\n            return False\n        raise", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:204", target="_top"];
  "lambda.parse_csv" [shape=box, tooltip="parse_csv(lines)\nlambda.py:125\n\ndef parse_csv(lines: Iterable[str]) -&gt; Iterable[Dict[str, Any]]:\n    it = iter(lines)\n    try:\n        header_line = next(it)\n    except StopIteration:\n        return\n    reader = csv.DictReader([header_line, *list(it)])\n    for row in reader:\n        yield {k: (v if v != &quot;&quot; else None) for k, v in row.items()}", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:125", target="_top"];
  "lambda.parse_jsonl" [shape=box, tooltip="parse_jsonl(lines)\nlambda.py:135\n\ndef parse_jsonl(lines: Iterable[str]) -&gt; Iterable[Dict[str, Any]]:\n    for line in lines:\n        try:\n            yield json.loads(line)\n        except Exception:\n            continue", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:135", target="_top"];
  "lambda.partition_value" [shape=box, tooltip="partition_value(record, event_time)\nlambda.py:105\n\ndef partition_value(record: Dict[str, Any], event_time: str) -&gt; str:\n    if PARTITION_BY == &quot;ingest_date&quot;:\n        return event_time[:10]  # YYYY-MM-DD\n    return str(record.get(PARTITION_BY, &quot;unknown&quot;))", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:105", target="_top"];
  "lambda.put_s3_gzip_lines" [shape=box, tooltip="put_s3_gzip_lines(bucket, key, lines)\nlambda.py:196\n\ndef put_s3_gzip_lines(bucket: str, key: str, lines: Iterable[str]) -&gt; None:\n    bio = io.BytesIO()\n    with gzip.GzipFile(fileobj=bio, mode=&quot;wb&quot;) as gz:\n        for line in lines:\n            gz.write((line + &quot;\n&quot;).encode(&quot;utf-8&quot;))\n    bio.seek(0)\n    s3.put_object(Bucket=bucket, Key=key, Body=bio, ContentType=&quot;application/x-ndjson&quot;, ContentEncoding=&quot;gzip&quot;)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:196", target="_top"];
  "lambda.send_dlq" [shape=box, tooltip="send_dlq(message)\nlambda.py:213\n\ndef send_dlq(message: Dict[str, Any]):\n    if not sqs:\n        return\n    try:\n        sqs.send_message(QueueUrl=DLQ_URL, MessageBody=json.dumps(message))\n    except Exception as e:\n        log.error(&quot;DLQ send failed: %s&quot;, e)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:213", target="_top"];
  "lambda.shard_writer" [shape=box, tooltip="shard_writer(base_prefix, event_time)\nlambda.py:221\n\ndef shard_writer(base_prefix: str, event_time: str) -&gt; Tuple:\n    &quot;&quot;&quot;\n    Returns a small writer that accumulates NDJSON, chunks by size/records, and writes to S3.\n    &quot;&quot;&quot;\n    shard_idx = 0\n    buf: List[str] = []\n    byte_count = 0\n\n    def flush():\n        nonlocal shard_idx, buf, byte_count\n        if not buf:\n            return None\n        shard_key = f&quot;{base_prefix}/part-{shard_idx:05d}.ndjson.gz&quot;\n        put_s3_gzip_lines(OUTPUT_BUCKET, shard_key, buf)\n        log.info(&quot;Wrote %s records to s3://%s/%s (%d shards)&quot;, len(buf), OUTPUT_BUCKET, shard_key, shard_idx + 1)\n        shard_idx += 1\n        buf = []\n        byte_count = 0\n\n    def write(rec: Dict[str, Any]):\n... (12 more lines)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:221", target="_top"];
  "lambda.snake_case" [shape=box, tooltip="snake_case(s)\nlambda.py:45\n\ndef snake_case(s: str) -&gt; str:\n    out = []\n    prev_lower = False\n    for ch in s:\n        if ch.isupper() and prev_lower:\n            out.append(&quot;_&quot;)\n        out.append(ch.lower())\n        prev_lower = ch.islower()\n    return &quot;&quot;.join(out).replace(&quot; &quot;, &quot;_&quot;)", href="vscode://file//Users/dinesh/Projects/Git_Projects/code-analyzer/lambda.py:45", target="_top"];
  "builtins.bool" [shape=ellipse, style=dashed, tooltip="builtins.bool"];
  "builtins.eval" [shape=ellipse, style=dashed, tooltip="builtins.eval"];
  "builtins.float" [shape=ellipse, style=dashed, tooltip="builtins.float"];
  "builtins.int" [shape=ellipse, style=dashed, tooltip="builtins.int"];
  "builtins.isinstance" [shape=ellipse, style=dashed, tooltip="builtins.isinstance"];
  "builtins.iter" [shape=ellipse, style=dashed, tooltip="builtins.iter"];
  "builtins.len" [shape=ellipse, style=dashed, tooltip="builtins.len"];
  "builtins.list" [shape=ellipse, style=dashed, tooltip="builtins.list"];
  "builtins.next" [shape=ellipse, style=dashed, tooltip="builtins.next"];
  "builtins.set" [shape=ellipse, style=dashed, tooltip="builtins.set"];
  "builtins.str" [shape=ellipse, style=dashed, tooltip="builtins.str"];
  "csv.DictReader" [shape=ellipse, style=dashed, tooltip="csv.DictReader"];
  "datetime.datetime.fromisoformat" [shape=ellipse, style=dashed, tooltip="datetime.datetime.fromisoformat"];
  "datetime.datetime.fromtimestamp" [shape=ellipse, style=dashed, tooltip="datetime.datetime.fromtimestamp"];
  "datetime.now" [shape=ellipse, style=dashed, tooltip="datetime.now"];
  "gzip.GzipFile" [shape=ellipse, style=dashed, tooltip="gzip.GzipFile"];
  "hashlib.md5" [shape=ellipse, style=dashed, tooltip="hashlib.md5"];
  "hashlib.sha256" [shape=ellipse, style=dashed, tooltip="hashlib.sha256"];
  "io.BytesIO" [shape=ellipse, style=dashed, tooltip="io.BytesIO"];
  "json.dumps" [shape=ellipse, style=dashed, tooltip="json.dumps"];
  "json.loads" [shape=ellipse, style=dashed, tooltip="json.loads"];
  "time.time" [shape=ellipse, style=dashed, tooltip="time.time"];
  "traceback.format_exc" [shape=ellipse, style=dashed, tooltip="traceback.format_exc"];
  "lambda.apply_spec_transforms" -> "lambda.coerce_type";
  "lambda.flush" -> "lambda.put_s3_gzip_lines";
  "lambda.get_writer" -> "lambda.shard_writer";
  "lambda.handler" -> "lambda._utc_now_iso";
  "lambda.handler" -> "lambda.apply_spec_transforms";
  "lambda.handler" -> "lambda.detect_format";
  "lambda.handler" -> "lambda.enrich_record";
  "lambda.handler" -> "lambda.get_writer";
  "lambda.handler" -> "lambda.iter_s3_object_lines";
  "lambda.handler" -> "lambda.load_transform_spec";
  "lambda.handler" -> "lambda.mask_fields";
  "lambda.handler" -> "lambda.normalize_keys";
  "lambda.handler" -> "lambda.object_exists";
  "lambda.handler" -> "lambda.parse_csv";
  "lambda.handler" -> "lambda.parse_jsonl";
  "lambda.handler" -> "lambda.partition_value";
  "lambda.handler" -> "lambda.send_dlq";
  "lambda.handler" -> "lambda.shard_writer";
  "lambda.mask_fields" -> "lambda.mask_value";
  "lambda.normalize_keys" -> "lambda.snake_case";
  "lambda.shard_writer" -> "lambda.flush";
  "lambda.shard_writer" -> "lambda.put_s3_gzip_lines";
  "lambda._utc_now_iso" -> "datetime.now" [style=dashed];
  "lambda.apply_spec_transforms" -> "builtins.eval" [style=dashed];
  "lambda.coerce_type" -> "builtins.float" [style=dashed];
  "lambda.coerce_type" -> "builtins.int" [style=dashed];
  "lambda.coerce_type" -> "builtins.isinstance" [style=dashed];
  "lambda.coerce_type" -> "builtins.str" [style=dashed];
  "lambda.coerce_type" -> "datetime.datetime.fromisoformat" [style=dashed];
  "lambda.coerce_type" -> "datetime.datetime.fromtimestamp" [style=dashed];
  "lambda.enrich_record" -> "builtins.iter" [style=dashed];
  "lambda.enrich_record" -> "builtins.next" [style=dashed];
  "lambda.flush" -> "builtins.len" [style=dashed];
  "lambda.get_writer" -> "builtins.str" [style=dashed];
  "lambda.handler" -> "builtins.bool" [style=dashed];
  "lambda.handler" -> "builtins.int" [style=dashed];
  "lambda.handler" -> "builtins.iter" [style=dashed];
  "lambda.handler" -> "builtins.list" [style=dashed];
  "lambda.handler" -> "builtins.next" [style=dashed];
  "lambda.handler" -> "builtins.set" [style=dashed];
  "lambda.handler" -> "builtins.str" [style=dashed];
  "lambda.handler" -> "hashlib.md5" [style=dashed];
  "lambda.handler" -> "json.dumps" [style=dashed];
  "lambda.handler" -> "time.time" [style=dashed];
  "lambda.handler" -> "traceback.format_exc" [style=dashed];
  "lambda.load_transform_spec" -> "builtins.isinstance" [style=dashed];
  "lambda.load_transform_spec" -> "json.loads" [style=dashed];
  "lambda.mask_value" -> "hashlib.sha256" [style=dashed];
  "lambda.mask_value" -> "json.dumps" [style=dashed];
  "lambda.parse_csv" -> "builtins.iter" [style=dashed];
  "lambda.parse_csv" -> "builtins.list" [style=dashed];
  "lambda.parse_csv" -> "builtins.next" [style=dashed];
  "lambda.parse_csv" -> "csv.DictReader" [style=dashed];
  "lambda.parse_jsonl" -> "json.loads" [style=dashed];
  "lambda.partition_value" -> "builtins.str" [style=dashed];
  "lambda.put_s3_gzip_lines" -> "gzip.GzipFile" [style=dashed];
  "lambda.put_s3_gzip_lines" -> "io.BytesIO" [style=dashed];
  "lambda.send_dlq" -> "json.dumps" [style=dashed];
  "lambda.shard_writer" -> "builtins.len" [style=dashed];
  "lambda.shard_writer" -> "json.dumps" [style=dashed];
  subgraph cluster_legend {
    label="Legend"; fontsize=10; style=dashed; color=gray;
    l_start [label="Start", shape=box, style=filled, fillcolor=lightblue];
    l_ext [label="External", shape=ellipse, style=dashed];
    l_cycle [label="Cycle Node", shape=doublecircle, color=red, penwidth=2];
    l_edge [label="Internal Edge", shape=point, width=0.1];
    l_extedge [label="External Edge (dashed)", shape=point, width=0.1];
  }
}
